{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa786ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train_reduced = 'E:/Heart_Disease_Project/data/x_train_reduced.csv'\n",
    "y_train = 'E:/Heart_Disease_Project/data/y_train.csv'\n",
    "\n",
    "x_test_reduced = 'E:/Heart_Disease_Project/data/x_test_reduced.csv'\n",
    "y_test = 'E:/Heart_Disease_Project/data/y_test.csv'\n",
    "\n",
    "x_train_reduced = pd.read_csv(x_train_reduced)\n",
    "y_train = pd.read_csv(y_train)\n",
    "\n",
    "x_test_reduced = pd.read_csv(x_test_reduced)\n",
    "y_test = pd.read_csv(y_test)\n",
    "\n",
    "# Logistic Regression\n",
    "param_logreg = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Decision Tree\n",
    "param_dt = {\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "param_rf = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# SVM\n",
    "param_svm = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3279f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tuning Logistic Regression ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tuning Decision Tree ...\n",
      "üîç Tuning Random Forest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1363: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tuning SVM ...\n",
      "\n",
      " Hyperparameter Tuning Results:\n",
      "                 Model                                        Best Params  \\\n",
      "0  Logistic Regression      {'solver': 'saga', 'penalty': 'l2', 'C': 100}   \n",
      "1        Decision Tree  {'min_samples_split': 2, 'min_samples_leaf': 1...   \n",
      "2        Random Forest  {'n_estimators': 100, 'min_samples_split': 5, ...   \n",
      "3                  SVM     {'kernel': 'poly', 'gamma': 'scale', 'C': 100}   \n",
      "\n",
      "   Best CV Score  \n",
      "0       0.874134  \n",
      "1       0.989027  \n",
      "2       0.990246  \n",
      "3       0.987807  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of models + parameter grids\n",
    "models_params = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), param_logreg),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), param_dt),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), param_rf),\n",
    "    \"SVM\": (SVC(probability=True, random_state=42), param_svm)\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "results = []\n",
    "\n",
    "for name, (model, params) in models_params.items():\n",
    "    print(f\"üîç Tuning {name} ...\")\n",
    "    \n",
    "    # RandomizedSearch for speed\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        n_iter=20,             \n",
    "        scoring=\"f1_weighted\", \n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(x_train_reduced, y_train)\n",
    "    \n",
    "    best_models[name] = random_search.best_estimator_\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": random_search.best_params_,\n",
    "        \"Best CV Score\": random_search.best_score_\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n Hyperparameter Tuning Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"tuning_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd08c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Evaluation for Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       101\n",
      "           1       0.86      0.87      0.86       104\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.86      0.86      0.86       205\n",
      "weighted avg       0.86      0.86      0.86       205\n",
      "\n",
      "\n",
      "üìä Final Evaluation for Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       101\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n",
      "\n",
      "üìä Final Evaluation for Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       101\n",
      "           1       1.00      0.97      0.99       104\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "üìä Final Evaluation for SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       101\n",
      "           1       1.00      0.97      0.99       104\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\nüìä Final Evaluation for {name}\")\n",
    "    y_pred = model.predict(x_test_reduced)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea744a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Final pipeline saved as models/final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "final_model = best_models[\"Random Forest\"]\n",
    "preprocessor = joblib.load(\"E:/Heart_Disease_Project/models/preprocessor.pkl\")\n",
    "\n",
    "# full pipeline = preprocessing + model\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", final_model)\n",
    "])\n",
    "\n",
    "# Save the pipeline as .pkl\n",
    "joblib.dump(final_pipeline, \"../models/final_model.pkl\")\n",
    "print(\"üíæ Final pipeline saved as models/final_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50036ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
